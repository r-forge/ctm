
R version 4.5.2 (2025-10-31) -- "[Not] Part in a Rumble"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "tram"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('tram')
Loading required package: mlt
Loading required package: basefun
Loading required package: variables
Loading required package: mvtnorm
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("Aareg")
> ### * Aareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Aareg
> ### Title: Aalen Additive Hazards Model
> ### Aliases: Aareg
> ### Keywords: models regression survival smooth
> 
> ### ** Examples
> 
> 
>   data("GBSG2", package = "TH.data")
>   library("survival")
>   GBSG2$time <- as.numeric(GBSG2$time)
>   GBSG2$y <- with(GBSG2, Surv(time, cens))
> 
>   ### Cox proportional hazards model
>   m1 <- Coxph(y ~ horTh, data = GBSG2, support = c(1, 1500))
>   logLik(m1)
'log Lik.' -2607.216 (df=8)
> 
>   ### Aalen additive hazards model with time-varying effects
>   m2 <- Aareg(y | horTh ~ 1, data = GBSG2, support = c(1, 1500))
>   logLik(m2)
'log Lik.' -2607.966 (df=12)
> 
>   ### compare the hazard functions
>   nd <- data.frame(horTh = unique(GBSG2$horTh))
>   col <- 1:2
>   lty <- 1:2
>   plot(as.mlt(m1), newdata = nd, type = "hazard", 
+        col = col, lty = lty[1], xlab = "time")
>   plot(as.mlt(m2), newdata = nd, type = "hazard", 
+        col = col, lty = 2, add = TRUE)
>   legend("topright", col = rep(col, each = 2), 
+          lty = rep(1:2), bty = "n",
+          legend = paste(rep(paste("horTh:", 
+                                   levels(nd$horTh)), each = 2),
+                         rep(c("Cox", "Aalen"), 2)))
> 
> 
> 
> 
> cleanEx()

detaching ‘package:survival’

> nameEx("BoxCox")
> ### * BoxCox
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: BoxCox
> ### Title: (Similar to) Box-Cox Models
> ### Aliases: BoxCox
> ### Keywords: models regression smooth
> 
> ### ** Examples
> 
> 
>   data("BostonHousing2", package = "mlbench")
> 
>   lm(cmedv ~ crim + zn + indus + chas + nox + rm + age + dis + 
+              rad + tax + ptratio + b + lstat, data = BostonHousing2)

Call:
lm(formula = cmedv ~ crim + zn + indus + chas + nox + rm + age + 
    dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
(Intercept)         crim           zn        indus        chas1          nox  
  3.637e+01   -1.062e-01    4.772e-02    2.325e-02    2.692e+00   -1.774e+01  
         rm          age          dis          rad          tax      ptratio  
  3.789e+00    5.749e-04   -1.502e+00    3.038e-01   -1.270e-02   -9.239e-01  
          b        lstat  
  9.228e-03   -5.307e-01  

> 
>   BoxCox(cmedv ~ chas + crim + zn + indus + nox + 
+                  rm + age + dis + rad + tax + ptratio + b + lstat, 
+                  data = BostonHousing2)

  Non-normal (Box-Cox-Type) Linear Regression Model 

Call:
BoxCox(formula = cmedv ~ chas + crim + zn + indus + nox + rm + 
    age + dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
       chas1         crim           zn        indus          nox           rm 
 0.614652802 -0.047232066  0.005875600  0.016212421 -4.848795925  0.400312601 
         age          dis          rad          tax      ptratio            b 
-0.001772639 -0.290827823  0.078787249 -0.003631922 -0.217394343  0.002701834 
       lstat 
-0.171195618 

Log-Likelihood:
 -1338.032 (df = 20)

> 
> 
> 
> cleanEx()
> nameEx("Colr")
> ### * Colr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Colr
> ### Title: Continuous Outcome Logistic Regression
> ### Aliases: Colr
> ### Keywords: models regression smooth
> 
> ### ** Examples
> 
> 
>   data("BostonHousing2", package = "mlbench")
> 
>   lm(cmedv ~ crim + zn + indus + chas + nox + rm + age + dis + 
+              rad + tax + ptratio + b + lstat, data = BostonHousing2)

Call:
lm(formula = cmedv ~ crim + zn + indus + chas + nox + rm + age + 
    dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
(Intercept)         crim           zn        indus        chas1          nox  
  3.637e+01   -1.062e-01    4.772e-02    2.325e-02    2.692e+00   -1.774e+01  
         rm          age          dis          rad          tax      ptratio  
  3.789e+00    5.749e-04   -1.502e+00    3.038e-01   -1.270e-02   -9.239e-01  
          b        lstat  
  9.228e-03   -5.307e-01  

> 
>   Colr(cmedv ~ chas + crim + zn + indus + nox + 
+                rm + age + dis + rad + tax + ptratio + b + lstat, 
+                data = BostonHousing2)

  Continuous Outcome Logistic Regression 

Call:
Colr(formula = cmedv ~ chas + crim + zn + indus + nox + rm + 
    age + dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
       chas1         crim           zn        indus          nox           rm 
-0.993333063  0.085869291 -0.008412791 -0.033955976  6.871901732 -1.414088427 
         age          dis          rad          tax      ptratio            b 
 0.007729050  0.460006325 -0.120067570  0.006420934  0.393875605 -0.006505173 
       lstat 
 0.293126064 

Log-Likelihood:
 -1308.809 (df = 20)

> 
> 
> 
> cleanEx()
> nameEx("Compris")
> ### * Compris
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Compris
> ### Title: Competing Risk Regression
> ### Aliases: Compris
> ### Keywords: models regression smooth survival
> 
> ### ** Examples
> 
>   
>   if (require("randomForestSRC")) {
+     library("survival")
+     
+     ## Competing risk data set involving follicular cell lymphoma
+     ##   (from doi:10.1002/9780470870709)
+     data("follic", package = "randomForestSRC")
+   
+     ## Therapy:
+     ### Radiotherapy alone (RT) or Chemotherapy + Radiotherapy (CMTRT)
+     follic$ch <- factor(as.character(follic$ch),
+       levels = c("N", "Y"), labels = c("RT", "CMTRT")) 
+   
+     ## Clinical state
+     follic$clinstg <- factor(follic$clinstg,
+       levels = 2:1, labels = c("II", "I"))
+   
+     ## Pre-processing as in Deresa & Van Keilegom (2023)
+     follic$time <- round(follic$time, digits = 3)
+     follic$age <- with(follic, (age - mean(age)) / sd(age)) ## standardised
+     follic$hgb <- with(follic, (hgb - mean(hgb)) / sd(hgb)) ## standardised 
+     
+     ## Setup `Surv' object for fitting Compris():
+     ### "status" indicator with levels:
+     ###   (1) independent censoring (admin_cens)
+     ###   (2) primary event of interest (relapse)
+     ###   (3) dependent censoring (death)
+     follic$status <- factor(follic$status,
+       levels = 0:2, labels = c("admin_cens", "relapse", "death"))
+     
+     follic$y <- with(follic, Surv(time = time, event = status))
+   
+     ## Fit a Gaussian Copula-based Cox Proportional Hazards Model with
+     ##   a marginal "Coxph" model for the primary event of interest and 
+     ##   a Weibull "Survreg" model for dependent censoring
+ 
+     m <- Compris(y ~ ch + age + hgb + clinstg, data = follic,
+                  optim = mltoptim(),    ### no numerical hessian
+                  args  = list(type = "ghalton", 
+                               M = 80))	### only 80 MC integration points
+                                         ### to make CRAN happy
+ 
+     ### log-likelihood
+     logLik(m)
+ 
+     ## Similar to Table 4 of Deresa & Van Keilegom (2023),
+     ## but using a Gaussian copula instead of a Gumbel copula.
+     ## marginal parameters
+     coef(m, type = "marginal")    
+     ## Kendall's tau
+     coef(m, type = "Kendall")
+   }
Loading required package: randomForestSRC

 randomForestSRC 3.4.4 
 
 Type rfsrc.news() to see new features, changes, and bug fixes. 
 

, , 1

              Event_relapse Event_death
Event_relapse     1.0000000   0.5367655
Event_death       0.5367655   1.0000000

> 
> 
> 
> cleanEx()

detaching ‘package:survival’, ‘package:randomForestSRC’

> nameEx("Coxph")
> ### * Coxph
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Coxph
> ### Title: Cox Proportional Hazards Model
> ### Aliases: Coxph
> ### Keywords: models regression survival smooth
> 
> ### ** Examples
> 
> 
>   data("GBSG2", package = "TH.data")
> 
>   library("survival")
>   (m1 <- coxph(Surv(time, cens) ~ horTh, data = GBSG2))
Call:
coxph(formula = Surv(time, cens) ~ horTh, data = GBSG2)

            coef exp(coef) se(coef)      z      p
horThyes -0.3640    0.6949   0.1250 -2.911 0.0036

Likelihood ratio test=8.82  on 1 df, p=0.002977
n= 686, number of events= 299 
> 
>   (m2 <- Coxph(Surv(time, cens) ~ horTh, data = GBSG2))

  Parametric Linear Cox Regression Model 

Call:
Coxph(formula = Surv(time, cens) ~ horTh, data = GBSG2)

Coefficients:
  horThyes 
-0.3657255 

Log-Likelihood:
 -2605.617 (df = 8)

> 
>   ### McLain & Ghosh (2013)
>   (m3 <- Coxph(Surv(time, cens) ~ horTh, data = GBSG2, 
+                frailty = "Gamma"))

Call:
Coxph(formula = Surv(time, cens) ~ horTh, data = GBSG2, frailty = "Gamma")

Type:  continuous linear transformation model (transformed GammaFrailty(rho = 0.7355937) distribution)
Log-Likelihood: -2605.532 (df = 8)

Coefficients: -7.336624 -3.834211 -3.834211 -2.16268 -1.692044 0.05005723 0.601836 -0.448755

> 
>   ### Wald intervals
>   confint(m1)
              2.5 %    97.5 %
horThyes -0.6090927 -0.118927
>   confint(m2)
              2.5 %     97.5 %
horThyes -0.6107864 -0.1206647
>   ### profile likelihood interval
>   confint(profile(m2))
     2.5 %     97.5 % 
-0.6148240 -0.1240763 
>   ### score interval
>   confint(score_test(m2))
              2.5 %     97.5 %
horThyes -0.6101594 -0.1213078
>   ### permutation score interval; uses permutation distribution
>   ### see coin::independence_test 
>   confint(perm_test(m2))
          2.5 %     97.5 %
[1,] -0.6066269 -0.1249074
> 
> 
> 
> 
> cleanEx()

detaching ‘package:survival’

> nameEx("Lehmann")
> ### * Lehmann
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Lehmann
> ### Title: Proportional Reverse Time Hazards Linear Regression
> ### Aliases: Lehmann
> ### Keywords: models regression smooth
> 
> ### ** Examples
> 
> 
>   data("BostonHousing2", package = "mlbench")
> 
>   lm(cmedv ~ crim + zn + indus + chas + nox + rm + age + dis + 
+              rad + tax + ptratio + b + lstat, data = BostonHousing2)

Call:
lm(formula = cmedv ~ crim + zn + indus + chas + nox + rm + age + 
    dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
(Intercept)         crim           zn        indus        chas1          nox  
  3.637e+01   -1.062e-01    4.772e-02    2.325e-02    2.692e+00   -1.774e+01  
         rm          age          dis          rad          tax      ptratio  
  3.789e+00    5.749e-04   -1.502e+00    3.038e-01   -1.270e-02   -9.239e-01  
          b        lstat  
  9.228e-03   -5.307e-01  

> 
>   Lehmann(cmedv ~ chas + crim + zn + indus + nox + 
+                   rm + age + dis + rad + tax + ptratio + b + lstat, 
+                   data = BostonHousing2)

  Proportional Reverse Time Hazards Linear Regression Model 

Call:
Lehmann(formula = cmedv ~ chas + crim + zn + indus + nox + rm + 
    age + dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
       chas1         crim           zn        indus          nox           rm 
 0.439589364 -0.046237859  0.006376011  0.025016648 -4.753717019  0.958525387 
         age          dis          rad          tax      ptratio            b 
-0.006640133 -0.310290944  0.061209639 -0.005393233 -0.245414357  0.002682457 
       lstat 
-0.170652486 

Log-Likelihood:
 -1310.117 (df = 20)

> 
> 
> 
> cleanEx()
> nameEx("Lm")
> ### * Lm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Lm
> ### Title: Normal Linear Model
> ### Aliases: Lm
> ### Keywords: models regression
> 
> ### ** Examples
> 
> 
>   data("BostonHousing2", package = "mlbench")
> 
>   lm(cmedv ~ crim + zn + indus + chas + nox + rm + age + dis + 
+              rad + tax + ptratio + b + lstat, data = BostonHousing2)

Call:
lm(formula = cmedv ~ crim + zn + indus + chas + nox + rm + age + 
    dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
(Intercept)         crim           zn        indus        chas1          nox  
  3.637e+01   -1.062e-01    4.772e-02    2.325e-02    2.692e+00   -1.774e+01  
         rm          age          dis          rad          tax      ptratio  
  3.789e+00    5.749e-04   -1.502e+00    3.038e-01   -1.270e-02   -9.239e-01  
          b        lstat  
  9.228e-03   -5.307e-01  

> 
>   Lm(cmedv ~ chas + crim + zn + indus + nox + 
+              rm + age + dis + rad + tax + ptratio + b + lstat, 
+              data = BostonHousing2)

  Normal Linear Regression Model 

Call:
Lm(formula = cmedv ~ chas + crim + zn + indus + nox + rm + age + 
    dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
        chas1          crim            zn         indus           nox 
 0.5804661474 -0.0229009319  0.0102915894  0.0050123394 -3.8255950258 
           rm           age           dis           rad           tax 
 0.8172202007  0.0001235862 -0.3238457686  0.0655027709 -0.0027396714 
      ptratio             b         lstat 
-0.1992323184  0.0019902893 -0.1144347471 

Log-Likelihood:
 -1494.245 (df = 15)

> 
> 
> 
> cleanEx()
> nameEx("Polr")
> ### * Polr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Polr
> ### Title: Ordered Categorical Regression
> ### Aliases: Polr
> ### Keywords: models regression
> 
> ### ** Examples
> 
> 
>   data("wine", package = "ordinal")
> 
>   library("MASS")
>   polr(rating ~ temp + contact, data = wine)
Call:
polr(formula = rating ~ temp + contact, data = wine)

Coefficients:
  tempwarm contactyes 
  2.503073   1.527786 

Intercepts:
      1|2       2|3       3|4       4|5 
-1.344374  1.250800  3.466871  5.006386 

Residual Deviance: 172.9838 
AIC: 184.9838 
> 
>   Polr(rating ~ temp + contact, data = wine)

  Proportional Odds Regression Model 

Call:
Polr(formula = rating ~ temp + contact, data = wine)

Coefficients:
  tempwarm contactyes 
  2.503109   1.527802 

Log-Likelihood:
 -86.49192 (df = 6)

> 
> 
> 
> 
> cleanEx()

detaching ‘package:MASS’

> nameEx("Survreg")
> ### * Survreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Survreg
> ### Title: Parametric Survival Models
> ### Aliases: Survreg
> ### Keywords: models regression survival
> 
> ### ** Examples
> 
> 
>   data("GBSG2", package = "TH.data")
> 
>   library("survival")
>   survreg(Surv(time, cens) ~ horTh, data = GBSG2)
Call:
survreg(formula = Surv(time, cens) ~ horTh, data = GBSG2)

Coefficients:
(Intercept)    horThyes 
  7.6084486   0.3059506 

Scale= 0.7780247 

Loglik(model)= -2632.1   Loglik(intercept only)= -2637.3
	Chisq= 10.36 on 1 degrees of freedom, p= 0.00129 
n= 686 
> 
>   Survreg(Surv(time, cens) ~ horTh, data = GBSG2)

  Weibull Linear Regression Model 

Call:
Survreg(formula = Surv(time, cens) ~ horTh, data = GBSG2)

Coefficients:
 horThyes 
0.3932258 

Log-Likelihood:
 -2632.096 (df = 3)

> 
> 
> 
> 
> cleanEx()

detaching ‘package:survival’

> nameEx("mmlt")
> ### * mmlt
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Mmlt
> ### Title: Multivariate Conditional Transformation Models
> ### Aliases: Mmlt
> ### Keywords: models
> 
> ### ** Examples
> 
> 
>   data("cars")
> 
>   ### fit unconditional bivariate distribution of speed and distance to stop
>   ## fit unconditional marginal transformation models
>   m_speed <- BoxCox(speed ~ 1, data = cars, support = ss <- c(4, 25), 
+                     add = c(-5, 5))
>   m_dist <- BoxCox(dist ~ 1, data = cars, support = sd <- c(0, 120), 
+                    add = c(-5, 5))
> 
>   ## fit multivariate unconditional transformation model
>   m_speed_dist <- Mmlt(m_speed, m_dist, formula = ~ 1, data = cars)
> 
>   ## log-likelihood
>   logLik(m_speed_dist)
'log Lik.' -348.4534 (df=15)
>   sum(predict(m_speed_dist, newdata = cars, type = "density", log = TRUE))
[1] -348.4534
> 
>   ## Wald test of independence of speed and dist (the "dist.speed.(Intercept)"
>   ## coefficient)
>   summary(m_speed_dist)

 

Call:
Mmlt(m_speed, m_dist, formula = ~1, data = cars)

Coefficients:
                       Estimate Std. Error z value Pr(>|z|)    
speed.Bs1(speed)        -2.3342     0.3667  -6.366 1.94e-10 ***
speed.Bs2(speed)        -1.2781     0.3095  -4.129 3.64e-05 ***
speed.Bs3(speed)        -1.2781     0.3095  -4.129 3.64e-05 ***
speed.Bs4(speed)         0.4782     0.5698   0.839  0.40128    
speed.Bs5(speed)         0.5184     0.2734   1.896  0.05800 .  
speed.Bs6(speed)         0.5184     0.2734   1.896  0.05799 .  
speed.Bs7(speed)         2.0653     0.3235   6.383 1.74e-10 ***
dist.Bs1(dist)          -2.6999     0.4591  -5.881 4.09e-09 ***
dist.Bs2(dist)          -0.3250     0.6272  -0.518  0.60434    
dist.Bs3(dist)           0.5147     0.4242   1.213  0.22507    
dist.Bs4(dist)           0.5147     0.4242   1.213  0.22507    
dist.Bs5(dist)           1.4484     0.8769   1.652  0.09860 .  
dist.Bs6(dist)           1.6857     0.5832   2.891  0.00385 ** 
dist.Bs7(dist)           2.3245     0.4504   5.161 2.46e-07 ***
dist.speed.(Intercept)  -1.6332     0.2735  -5.972 2.34e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Log-Likelihood:
 -348.4534 (df = 15)

> 
>   ## LR test comparing to independence model
>   LR <- 2 * (logLik(m_speed_dist) - logLik(m_speed) - logLik(m_dist))
>   pchisq(LR, df = 1, lower.tail = FALSE)
'log Lik.' 1.164859e-15 (df=15)
> 
>   ## constrain lambda to zero and fit independence model
>   ## => log-likelihood is the sum of the marginal log-likelihoods
>   mI <- Mmlt(m_speed, m_dist, formula = ~1, data = cars, 
+              fixed = c("dist.speed.(Intercept)" = 0))
Warning in max(abs(pg)) :
  no non-missing arguments to max; returning -Inf
>   logLik(m_speed) + logLik(m_dist)
'log Lik.' -380.5183 (df=7)
>   logLik(mI)
'log Lik.' -380.5183 (df=14)
> 
>   ## linear correlation, ie Pearson correlation of speed and dist after
>   ## transformation to bivariate normality
>   (r <- coef(m_speed_dist, type = "Corr"))
, , 1

          speed      dist
speed 1.0000000 0.8528312
dist  0.8528312 1.0000000

>   
>   ## Spearman's rho (rank correlation) of speed and dist on original scale
>   (rs <- coef(m_speed_dist, type = "Spearman"))
, , 1

          speed      dist
speed 1.0000000 0.8413433
dist  0.8413433 1.0000000

> 
>   ## evaluate joint and marginal densities (needs to be more user-friendly)
>   nd <- expand.grid(c(nd_s <- mkgrid(m_speed, 100), nd_d <- mkgrid(m_dist, 100)))
>   nd$d <- predict(m_speed_dist, newdata = nd, type = "density")
> 
>   ## compute marginal densities
>   nd_s <- as.data.frame(nd_s)
>   nd_s$d <- predict(m_speed_dist, newdata = nd_s, margins = 1L,
+                     type = "density")
>   nd_d <- as.data.frame(nd_d)
>   nd_d$d <- predict(m_speed_dist, newdata = nd_d, margins = 2L, 
+                     type = "density")
> 
>   ## plot bivariate and marginal distribution
>   col1 <- rgb(.1, .1, .1, .9)
>   col2 <- rgb(.1, .1, .1, .5)
>   w <- c(.8, .2)
>   layout(matrix(c(2, 1, 4, 3), nrow = 2), width = w, height = rev(w))
>   par(mai = c(1, 1, 0, 0) * par("mai"))
>   sp <- unique(nd$speed)
>   di <- unique(nd$dist)
>   d <- matrix(nd$d, nrow = length(sp))
>   contour(sp, di, d, xlab = "Speed (in mph)", ylab = "Distance (in ft)", xlim = ss, ylim = sd,
+           col = col1)
>   points(cars$speed, cars$dist, pch = 19, col = col2)
>   mai <- par("mai")
>   par(mai = c(0, 1, 0, 1) * mai)
>   plot(d ~ speed, data = nd_s, xlim = ss, type = "n", axes = FALSE, 
+        xlab = "", ylab = "")
>   polygon(nd_s$speed, nd_s$d, col = col2, border = FALSE)
>   par(mai = c(1, 0, 1, 0) * mai)
>   plot(dist ~ d, data = nd_d, ylim = sd, type = "n", axes = FALSE, 
+        xlab = "", ylab = "")
>   polygon(nd_d$d, nd_d$dist, col = col2, border = FALSE)
> 
>   ### NOTE: marginal densities are NOT normal, nor is the joint
>   ### distribution. The non-normal shape comes from the data-driven 
>   ### transformation of both variables to joint normality in this model.
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("mtram")
> ### * mtram
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mtram
> ### Title: Transformation Models for Clustered Data
> ### Aliases: mtram
> ### Keywords: models
> 
> ### ** Examples
> 
> 
>   if (require("lme4")) {
+       ### linear mixed model
+       sleep_lmer <- lmer(Reaction ~ Days + (Days | Subject), 
+                          data = sleepstudy, REML = FALSE)
+ 
+       ### marginal transformation model
+       sleep_LM <- Lm(Reaction ~ Days, data = sleepstudy)
+       sleep_LMmer <- mtram(sleep_LM, ~ (Days | Subject), data = sleepstudy)
+ 
+       ### the same
+       logLik(sleep_lmer)
+       logLik(sleep_LMmer)
+ 
+       ### Lm / mtram estimate standardised effects
+       sdinv <- 1 / summary(sleep_lmer)$sigma
+       fixef(sleep_lmer) * c(-1, 1) * sdinv
+       coef(sleep_LMmer)[c("(Intercept)", "Days")]
+   }
Loading required package: lme4
Loading required package: Matrix
(Intercept)        Days 
 -9.8252286   0.4091449 
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("perm_test")
> ### * perm_test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: perm_test
> ### Title: Permutation Transformation Tests
> ### Aliases: perm_test perm_test.tram
> 
> ### ** Examples
> 
> 
>   ## Tritiated Water Diffusion Across Human Chorioamnion
>   ## Hollander and Wolfe (1999, p. 110, Tab. 4.1)
>   diffusion <- data.frame(
+       pd = c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46,
+              1.15, 0.88, 0.90, 0.74, 1.21),
+       age = factor(rep(c("At term", "12-26 Weeks"), c(10, 5)))
+   )
> 
>   ### plot the two quantile functions
>   boxplot(pd ~ age, data = diffusion)
> 
>   ### the Wilcoxon rank sum test, with a confidence interval
>   ### for a median shift
>   wilcox.test(pd ~ age, data = diffusion, conf.int = TRUE, exact = TRUE)

	Wilcoxon rank sum exact test

data:  pd by age
W = 15, p-value = 0.2544
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 -0.76  0.15
sample estimates:
difference in location 
                -0.305 

> 
>   ### a corresponding parametric transformation model with a log-odds ratio
>   ### difference parameter, ie a difference on the log-odds scale
>   md <- Colr(pd ~ age, data = diffusion)
> 
>   ### assess model fit by plotting estimated distribution fcts
>   agef <- sort(unique(diffusion$age))
>   col <- c("black", "darkred")
>   plot(as.mlt(md), newdata = data.frame(age = agef),
+        type = "distribution", col = col)
>   legend("bottomright", col = col, lty = 1, legend = levels(agef), 
+          bty = "n", pch = 19)
>   ## compare with ECDFs: not too bad (but not good, either)
>   npfit <- with(diffusion, tapply(pd, age, ecdf))
>   lines(npfit[[1]], col = col[1])
>   lines(npfit[[2]], col = col[2])
> 
>   ### Wald confidence interval
>   confint(md)
               2.5 %    97.5 %
ageAt term -3.215749 0.5977511
> 
>   ### Likelihood confidence interval
>   confint(profile(md))
     2.5 %     97.5 % 
-3.3117320  0.5573283 
> 
>   ### Score confidence interval
>   confint(score_test(md))
               2.5 %    97.5 %
ageAt term -3.165315 0.5335403
>   confint(score_test(md, Taylor = TRUE))
Warning in score_test.tram(md, Taylor = TRUE) :
  cannot compute score interval, returning Wald interval
               2.5 %    97.5 %
ageAt term -3.215749 0.5977511
> 
>   ### exact permutation score test
>   (pt <- perm_test(md, confint = TRUE, distribution = "exact"))

	Exact Permutation Transformation Score Test

data:  Colr(formula = pd ~ age, data = diffusion)
Z = 1.3167, p-value = 0.1948
alternative hypothesis: true log-odds ratio for ageAt term is not equal to 0
95 percent confidence interval:
 -3.231826  0.568369
sample estimates:
log-odds ratio for ageAt term 
                    -1.308999 

>   (pt <- perm_test(md, confint = TRUE, distribution = "exact", 
+                    Taylor = TRUE))
Warning in perm_test.tram(md, confint = TRUE, distribution = "exact", Taylor = TRUE) :
  cannot compute score interval, returning Wald interval

	Exact Permutation Transformation Score Test

data:  Colr(formula = pd ~ age, data = diffusion)
Z = 1.3167, p-value = 0.1948
alternative hypothesis: true log-odds ratio for ageAt term is not equal to 0
95 percent confidence interval:
 -3.2871861  0.6364507
sample estimates:
log-odds ratio for ageAt term 
                    -1.308999 

> 
>   ### compare with probabilistic indices obtained from asht::wmwTest
>   if (require("asht", warn.conflicts = FALSE)) {
+       print(wt2 <- wmwTest(pd ~ I(relevel(age, "At term")), 
+                       data = diffusion, method = "exact.ce"))
+       ### as log-odds ratios
+       print(PI(prob = wt2$conf.int))
+       print(PI(prob = wt2$estimate))
+   }
Loading required package: asht
Loading required package: exact2x2
Loading required package: exactci
Loading required package: ssanv
Loading required package: testthat
Loading required package: bpcp
Loading required package: survival
Loading required package: ggplot2

Attaching package: ‘ggplot2’

The following object is masked from ‘package:variables’:

    unit

Loading required package: coin

Attaching package: ‘coin’

The following object is masked from ‘package:testthat’:

    expectation

The following object is masked from ‘package:variables’:

    support


	exact Wilcoxon-Man-Whitney test (confidence interval requires
	proportional odds assumption, but test does not)

data:  pd by I(relevel(age, "At term"))
Mann-Whitney estimate = 0.3, p-value = 0.2544
alternative hypothesis: two distributions are not equal
95 percent confidence interval:
 0.08292978 0.63269022
sample estimates:
Mann-Whitney estimate 
                  0.3 

[1] -3.4695871  0.8136834
Mann-Whitney estimate 
            -1.263612 
> 
> 
> 
> cleanEx()

detaching ‘package:asht’, ‘package:coin’, ‘package:bpcp’,
  ‘package:ggplot2’, ‘package:survival’, ‘package:exact2x2’,
  ‘package:exactci’, ‘package:testthat’, ‘package:ssanv’

> nameEx("robust_score_test")
> ### * robust_score_test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: robust_score_test
> ### Title: Doubly Robust Transformation Score Test
> ### Aliases: robust_score_test robust_score_test.tram
> 
> ### ** Examples
> 
> data("mtcars")
> ### Linear shift tram
> m <- Lm(mpg ~ cyl + disp, data = mtcars)
> robust_score_test(m, parm = "cyl")
Loading required namespace: ranger

	Doubly-robust Transformation Score Test

data:  Lm(formula = mpg ~ cyl + disp, data = mtcars)
Z = 1.3903, p-value = 0.1644
alternative hypothesis: true standardised difference for cyl is not equal to 0

> ### Linear shift-scale tram
> m2 <- Lm(mpg ~ cyl | disp, data = mtcars)
> robust_score_test(m2, parm = "cyl")

	Doubly-robust Transformation Score Test

data:  Lm(formula = mpg ~ cyl | disp, data = mtcars)
Z = 1.2078, p-value = 0.2271
alternative hypothesis: true standardised difference for cyl is not equal to 0

> robust_score_test(m2, parm = "scl_disp")

	Doubly-robust Transformation Score Test

data:  Lm(formula = mpg ~ cyl | disp, data = mtcars)
Z = 2.1356, p-value = 0.03271
alternative hypothesis: true standardised difference for scl_disp is not equal to 0

> ### Stratified linear shift tram
> m3 <- Lm(mpg | 0 + disp ~ cyl, data = mtcars)
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
> robust_score_test(m3, parm = "cyl")
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE

	Doubly-robust Transformation Score Test

data:  Lm(formula = mpg | 0 + disp ~ cyl, data = mtcars)
Z = 1.2269, p-value = 0.2199
alternative hypothesis: true standardised difference for cyl is not equal to 0

> ### Stratified linear shift-scale tram
> m4 <- Lm(mpg | 0 + disp ~ cyl | cyl, data = mtcars)
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in tram(td, transformation = "linear", distribution = "Normal",  :
  Models with both strata and scale terms are highly experimental
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
> robust_score_test(m4, parm = "cyl")
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE
Warning in model.matrix.box_bases(object = list(iresponse = function (data,  :
  use scale = TRUE in as.basis.formula with sumcontr = TRUE

	Doubly-robust Transformation Score Test

data:  Lm(formula = mpg | 0 + disp ~ cyl | cyl, data = mtcars)
Z = 1.1843, p-value = 0.2363
alternative hypothesis: true standardised difference for cyl is not equal to 0

> 
> 
> 
> 
> cleanEx()
> nameEx("tram-methods")
> ### * tram-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tram-methods
> ### Title: Methods for Stratified Linear Transformation Models
> ### Aliases: as.mlt.tram model.frame.tram model.matrix.tram
> ###   model.matrix.stram coef.tram coef.Lm coef.Survreg vcov.tram
> ###   logLik.tram estfun.tram predict.tram predict.stram residuals.tram
> ###   plot.tram plot.ROCtram PI PI.tram PI.default OVL OVL.tram OVL.default
> ###   TV TV.tram TV.default L1 L1.tram L1.default ROC ROC.tram ROC.default
> 
> ### ** Examples
> 
> 
>     data("BostonHousing2", package = "mlbench")
> 
>     ### fit non-normal Box-Cox type linear model with two
>     ### baseline functions (for houses near and off Charles River)
>     BC_BH_2 <- BoxCox(cmedv | 0 + chas ~ crim + zn + indus + nox + 
+                       rm + age + dis + rad + tax + ptratio + b + lstat,
+                       data = BostonHousing2)
>     logLik(BC_BH_2)
'log Lik.' -1334.509 (df=26)
> 
>     ### classical likelihood inference
>     summary(BC_BH_2)

 (Stratified) Non-normal (Box-Cox-Type) Linear Regression Model 

Call:
BoxCox(formula = cmedv | 0 + chas ~ crim + zn + indus + nox + 
    rm + age + dis + rad + tax + ptratio + b + lstat, data = BostonHousing2)

Coefficients:
          Estimate Std. Error z value Pr(>|z|)    
crim    -0.0467906  0.0074130  -6.312 2.76e-10 ***
zn       0.0061513  0.0029332   2.097    0.036 *  
indus    0.0140681  0.0131135   1.073    0.283    
nox     -4.9487919  0.8464110  -5.847 5.01e-09 ***
rm       0.4368418  0.0948225   4.607 4.09e-06 ***
age     -0.0016568  0.0028368  -0.584    0.559    
dis     -0.2991249  0.0437646  -6.835 8.21e-12 ***
rad      0.0811888  0.0142694   5.690 1.27e-08 ***
tax     -0.0037180  0.0008041  -4.624 3.76e-06 ***
ptratio -0.2184113  0.0285718  -7.644 2.11e-14 ***
b        0.0026673  0.0005776   4.618 3.87e-06 ***
lstat   -0.1669453  0.0123199 -13.551  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Log-Likelihood:
 -1334.509 (df = 26)
Likelihood-ratio Test: Chisq = 817.2314 on 12 degrees of freedom; p = < 2.2e-16

> 
>     ### coefficients of the linear predictor
>     coef(BC_BH_2)
        crim           zn        indus          nox           rm          age 
-0.046790563  0.006151332  0.014068066 -4.948791933  0.436841809 -0.001656839 
         dis          rad          tax      ptratio            b        lstat 
-0.299124862  0.081188783 -0.003717984 -0.218411314  0.002667338 -0.166945349 
> 
>     ### plot linear predictor (mean of _transformed_ response) 
>     ### vs. observed values
>     plot(predict(BC_BH_2, type = "lp"), BostonHousing2$cmedv)
> 
>     ### all coefficients
>     coef(BC_BH_2, with_baseline = TRUE)
Bs1(cmedv):chas0 Bs2(cmedv):chas0 Bs3(cmedv):chas0 Bs4(cmedv):chas0 
   -13.299892745    -11.572055177    -11.572055179     -4.413500468 
Bs5(cmedv):chas0 Bs6(cmedv):chas0 Bs7(cmedv):chas0 Bs1(cmedv):chas1 
    -2.922815888     -2.922815896     -2.176114273    -17.466541536 
Bs2(cmedv):chas1 Bs3(cmedv):chas1 Bs4(cmedv):chas1 Bs5(cmedv):chas1 
   -17.466541536     -8.197577847     -4.375130082     -4.375130049 
Bs6(cmedv):chas1 Bs7(cmedv):chas1             crim               zn 
    -4.375130134     -3.375504890     -0.046790563      0.006151332 
           indus              nox               rm              age 
     0.014068066     -4.948791933      0.436841809     -0.001656839 
             dis              rad              tax          ptratio 
    -0.299124862      0.081188783     -0.003717984     -0.218411314 
               b            lstat 
     0.002667338     -0.166945349 
> 
>     ### compute predicted median along with 10% and 90% quantile for the first
>     ### observations
>     predict(BC_BH_2, newdata = BostonHousing2[1:3,], type = "quantile",
+             prob = c(.1, .5, .9))
       
prob        [,1]     [,2]     [,3]
    0.1 22.77239 19.83903 23.39704
    0.5 27.98349 23.65863 29.08549
    0.9 38.50440 29.55907 41.48202
> 
>     ### plot the predicted density for these observations
>     plot(BC_BH_2, newdata = BostonHousing2[1:3, -1],
+          which = "distribution", type = "density", K = 1000)
> 
>     ### evaluate the two baseline transformations, with confidence intervals
>     nd <- model.frame(BC_BH_2)[1:2, -1]
>     nd$chas <- factor(c("0", "1"))
>     library("colorspace")
>     col <- diverge_hcl(2, h = c(246, 40), c = 96, l = c(65, 90))
>     fill <- diverge_hcl(2, h = c(246, 40), c = 96, l = c(65, 90), alpha = .3)
>     plot(BC_BH_2, which = "baseline only", newdata = nd, col = col,
+          confidence = "interval", fill = fill, lwd = 2,
+          xlab = "Median Value", ylab = expression(h[Y]))
>     legend("bottomright", lty = 1, col = col, 
+             title = "Near Charles River", legend = c("no", "yes"), bty = "n")
> 
>     ### cars data; with quantile functions
>     plot(dist ~ speed, data = cars)
>     m <- Colr(dist ~ speed, data = cars)
>     q <- predict(as.mlt(m), newdata = data.frame(speed = s <- 7:20),
+                  type = "quantile", prob = c(1, 5, 9) / 10)
>     lines(s, q[1,])
>     lines(s, q[2,])
>     lines(s, q[3,])
> 
>     nd <- data.frame(speed = s <- as.double(1:5 * 5))
>     
>     # Prob(dist at speed s > dist at speed 0)
>     # speed 0 is reference, not a good choice here
>     PI(m, newdata = nd)
          [,1]     [,2]      [,3]      [,4]      [,5]
[1,] 0.8593495 0.978335 0.9975546 0.9997618 0.9999786
> 
>     # Prob(dist at speed s > dist at speed 15)
>     lp15 <- c(predict(m, newdata = data.frame(speed = 15)))
>     PI(m, newdata = nd, reference = lp15)
           [,1]      [,2] [,3]      [,4]     [,5]
[1,] 0.02166504 0.1406505  0.5 0.8593495 0.978335
>     PI(m, newdata = nd, reference = nd[3,,drop = FALSE])
           [,1]      [,2] [,3]      [,4]     [,5]
[1,] 0.02166504 0.1406505  0.5 0.8593495 0.978335
> 
>     # Prob(dist at speed s' > dist at speed s)
>     PI(m, newdata = nd, reference = nd)
          1         2         3         4
2 0.8593495                              
3 0.9783350 0.8593495                    
4 0.9975546 0.9783350 0.8593495          
5 0.9997618 0.9975546 0.9783350 0.8593495
>     # essentially:
>     lp <- predict(m, newdata = nd)
>     PI(object = dist(lp))
          1         2         3         4
2 0.8593495                              
3 0.9783350 0.8593495                    
4 0.9975546 0.9783350 0.8593495          
5 0.9997618 0.9975546 0.9783350 0.8593495
>     # same, with simultaneous confidence intervals
>     PI(m, newdata = nd, reference = nd, conf.level = .95)
     Estimate       lwr       upr
1-2 0.8593495 0.7811056 0.9141291
1-3 0.9783350 0.9324841 0.9937147
2-3 0.8593495 0.7811056 0.9141291
1-4 0.9975546 0.9835574 0.9996740
2-4 0.9783350 0.9324841 0.9937147
3-4 0.8593495 0.7811056 0.9141291
1-5 0.9997618 0.9965137 0.9999854
2-5 0.9975546 0.9835574 0.9996740
3-5 0.9783350 0.9324841 0.9937147
4-5 0.8593495 0.7811056 0.9141291
attr(,"conf.level")
[1] 0.95
attr(,"calpha")
[1] 1.960362
> 
>     # plot ROC curves + confidence bands
>     # compare speed 20 and 25 to speed 15
>     plot(ROC(m, newdata = nd[4:5,,drop = FALSE],
+              reference = nd[3,,drop = FALSE],
+              conf.level = 0.95))
> 
>     # Overlap of conditional densities at speed s' and s
>     OVL(m, newdata = nd, reference = nd)
            1           2           3           4
2 0.419779466                                    
3 0.131832586 0.419779466                        
4 0.036802262 0.131832586 0.419779466            
5 0.009910296 0.036802262 0.131832586 0.419779466
> 
>     ### ROC analysis (takes too long for CRAN Windows)
>     if (require("mlbench") && .Platform$OS.type != "windows") {
+ 
+         layout(matrix(1:4, nrow = 2))
+         data("PimaIndiansDiabetes2", package = "mlbench")
+         dia <- sort(unique(PimaIndiansDiabetes2$diabetes))
+         nd <- data.frame(diabetes = dia, 
+                          age = 29, mass = 32) ### median values
+ 
+         ### unconditional ROC analysis: glucose tolerance test
+         m0 <- Colr(glucose ~ diabetes, data = PimaIndiansDiabetes2)
+         # ROC curve + confidence band
+         plot(ROC(m0, newdata = nd[2,,drop = FALSE], conf.level = .95)) 
+         # Wald interval for AUC
+         PI(m0, newdata = nd[2,,drop = FALSE], conf.level = .95)
+         # score interval for AUC
+         PI(-c(coef(m0), score_test(m0)$conf.int[2:1]))
+ 
+         ### adjusted ROC analysis for age and mass
+         m1 <- Colr(glucose ~ diabetes + age + mass, data = PimaIndiansDiabetes2)
+         # ROC curve + confidence band (this is the same for all ages /
+         # masses)
+         plot(ROC(m1, newdata = nd[2,,drop = FALSE], 
+                      reference = nd[1,,drop = FALSE], 
+                  conf.level = .95))
+         # Wald interval for adjusted AUC
+         PI(m1, newdata = nd[2,,drop = FALSE], reference = nd[1,,drop = FALSE], 
+            conf.level = .95)
+         # Score interval for adjusted AUC
+         PI(-c(coef(m1)[1], score_test(m1, names(coef(m1))[1])$conf.int[2:1]))
+ 
+         ### conditional ROC analysis: AUC regression ~ age + mass
+         m2 <- Colr(glucose ~ diabetes * (age + mass), data = PimaIndiansDiabetes2)
+         # ROC curve for a person with age = 29 and mass = 32
+         plot(ROC(m2, newdata = nd[2,,drop = FALSE], 
+                      reference = nd[1,,drop = FALSE], 
+                  conf.level = .95))
+         # AUC for persons ages 21:81, all with mass = 32
+         nd1 <- data.frame(diabetes = nd[1,"diabetes"], age = 21:81, mass = 32)
+         nd2 <- data.frame(diabetes = nd[2,"diabetes"], age = 21:81, mass = 32)
+         auc <- PI(m2, newdata = nd2, reference = nd1, one2one = TRUE,
+                   conf.level = 0.95)
+         plot(nd1$age, auc[, "Estimate"], xlab = "Age (in years)", ylab =
+              "AUC", ylim = c(0, 1), type = "l")
+         lines(nd1$age, auc[, "lwr"], lty = 3)
+         lines(nd1$age, auc[, "upr"], lty = 3)
+     }
Loading required package: mlbench
> 
> 
> 
> cleanEx()

detaching ‘package:mlbench’, ‘package:colorspace’

> nameEx("tram")
> ### * tram
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tram
> ### Title: Stratified Linear Transformation Models
> ### Aliases: tram tram_data
> ### Keywords: models regression smooth survival
> 
> ### ** Examples
> 
> 
>   data("BostonHousing2", package = "mlbench")
> 
>   ### unconstrained regression coefficients
>   ### BoxCox calls tram internally
>   m1 <- BoxCox(cmedv ~ chas + crim + zn + indus + nox + 
+                rm + age + dis + rad + tax + ptratio + b + lstat, 
+                data = BostonHousing2)
> 
>   ### now with two constraints on regression coefficients
>   m2 <- BoxCox(cmedv ~ chas + crim + zn + indus + nox + 
+                rm + age + dis + rad + tax + ptratio + b + lstat, 
+                data = BostonHousing2, 
+                constraints = c("crim >= 0", "chas1 + rm >= 1.5"))
>   coef(m1)
       chas1         crim           zn        indus          nox           rm 
 0.614652802 -0.047232066  0.005875600  0.016212421 -4.848795925  0.400312601 
         age          dis          rad          tax      ptratio            b 
-0.001772639 -0.290827823  0.078787249 -0.003631922 -0.217394343  0.002701834 
       lstat 
-0.171195618 
>   coef(m2)
        chas1          crim            zn         indus           nox 
 9.780091e-01 -2.971056e-08  4.364899e-03  1.608561e-02 -4.437389e+00 
           rm           age           dis           rad           tax 
 5.219909e-01 -2.746547e-03 -2.592862e-01  4.961829e-02 -3.216593e-03 
      ptratio             b         lstat 
-2.031165e-01  3.033473e-03 -1.667881e-01 
> 
>   K <- matrix(0, nrow = 2, ncol = length(coef(m2)))
>   colnames(K) <- names(coef(m2))
>   K[1, "crim"] <- 1
>   K[2, c("chas1", "rm")] <- 1
>   m3 <- BoxCox(cmedv ~ chas + crim + zn + indus + nox + 
+                rm + age + dis + rad + tax + ptratio + b + lstat, 
+                data = BostonHousing2, 
+                constraints = list(K, c(0, 1.5)))
>   all.equal(coef(m2), coef(m3))
[1] TRUE
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  24.653 0.171 24.889 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
