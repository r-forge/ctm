
R version 3.1.3 (2015-03-09) -- "Smooth Sidewalk"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> library("mlt")
Loading required package: basefun
Loading required package: Matrix

Attaching package: 'Matrix'

The following objects are masked from 'package:base':

    crossprod, tcrossprod

Loading required package: polynom
Loading required package: numDeriv
> library("survival")
> set.seed(29)
> 
> ### true dgp
> rY <- function(n, ...) rexp(n, ...)
> pY <- function(x, ...) pexp(x, ...)
> dY <- function(x, ...) dexp(x, ...)
> 
> ### tree groups
> gf <- gl(3, 1)
> g <- rep(gf, 100)
> y <- rY(length(g), rate = (1:nlevels(g))[g])
> mydata <- data.frame(y = y, g = g)
> 
> boxplot(y ~ g, data = mydata)
> 
> ### uncensored, Cox model, h = bernstein
> Bb <- Bernstein_basis(order = 5, support = c(0, max(y) + .1),
+                       ui = "increasing", var = "y")
> s <- as.basis(~ g, data = data.frame(g = gf), remove_intercept = TRUE)
> m <- model(response = Bb, shifting = s, todist = "MinExtrVal")
> (cf1 <- coef(opt <- mlt(m, data = mydata)))
Gradient[1] TRUE
Hessian:[1] TRUE
    Bs1(y)     Bs2(y)     Bs3(y)     Bs4(y)     Bs5(y)     Bs6(y)         g2 
-2.5706816  1.1035997  1.1035998  1.1035998  1.1035998  1.8004156  0.9323813 
        g3 
 1.2627530 
> coef(cph <- coxph(Surv(y, rep(TRUE, nrow(mydata))) ~ g, data = mydata))
      g2       g3 
0.699808 1.022699 
> yn <- generate(Bb, 50)$y
> yn <- yn[yn > 0]
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn, type = "trafo"), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> ### h = c(log, bernstein)
> lb <- log_basis(varname = "y", support = c(0, max(y)))
> m <- model(response = c(blog = lb, bBern = Bb), shifting = s, todist = "MinExtrVal")
> (cf1 <- coef(opt <- mlt(m, data = mydata)))
Gradient[1] "Mean relative difference: 1.113868e-07"
Hessian:[1] "Mean relative difference: 7.991511e-08"
              [,1]
 [1,]  0.838722228
 [2,] -0.305718055
 [3,] -0.002506204
 [4,] -0.002506189
 [5,] -0.002506174
 [6,] -0.002506159
 [7,]  0.275029639
 [8,]  0.764301899
 [9,]  1.068694530
> ## sample from this model
> nd <- samplefrom(opt, newdata = data.frame(g = gf), n = 100)
> (cf2 <- coef(opt2 <- mlt(m, data = nd)))
Gradient[1] TRUE
Hessian:[1] TRUE
            [,1]
 [1,]  1.0961758
 [2,] -0.2231665
 [3,] -0.2231665
 [4,] -0.2231665
 [5,] -0.2231665
 [6,] -0.2231665
 [7,]  0.5456321
 [8,]  0.8772897
 [9,]  1.0475200
> cf1 - cf2
             [,1]
 [1,] -0.25745354
 [2,] -0.08255151
 [3,]  0.22066033
 [4,]  0.22066033
 [5,]  0.22066033
 [6,]  0.22066033
 [7,] -0.27060245
 [8,] -0.11298779
 [9,]  0.02117453
> ## visualise
> yn <- generate(Bb, 50)$y
> yn <- yn[yn > 0]
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn, type = "trafo"), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> ### right censoring
> mydata <- data.frame(y = Surv(y, sample(0:1, length(y), replace = TRUE)), g = g)
> coef(opt <- mlt(m, data = mydata))
Gradient[1] TRUE
Hessian:[1] TRUE
            [,1]
 [1,]  0.8548846
 [2,] -0.8701500
 [3,] -0.7839356
 [4,] -0.7839356
 [5,] -0.7839356
 [6,] -0.7839356
 [7,] -0.2774258
 [8,]  0.8692641
 [9,]  1.1418617
> coef(cph <- coxph(y ~ g, data = mydata))
       g2        g3 
0.7891759 1.0616941 
> 
> ### left censoring
> mydata <- data.frame(y = Surv(y, sample(0:1, length(y), replace = TRUE), type = "left"), g = g)
> coef(opt <- mlt(m, data = mydata))
Gradient[1] TRUE
Hessian:[1] TRUE
             [,1]
 [1,]  0.38199840
 [2,] -0.04273012
 [3,]  0.97761138
 [4,]  0.97761140
 [5,]  0.97761141
 [6,]  0.97761143
 [7,]  1.19849383
 [8,]  0.33286413
 [9,]  0.53880027
> 
> ### interval censoring
> Bb <- Bernstein_basis(order = 5, support = c(0, max(y + 1) + .1),
+                       ui = "increasing", var = "y")
> mydata <- data.frame(y = Surv(y, y + 1, sample(0:3, length(y), replace = TRUE), type = "interval"), 
+                      g = g)
> m <- model(response = c(blog = lb, bBern = Bb), shifting = s, todist = "MinExtrVal")
> coef(opt <- mlt(m, data = mydata))
Gradient[1] "Mean relative difference: 3.713344e-08"
Hessian:[1] TRUE
            [,1]
 [1,]  0.5103188
 [2,] -1.2644858
 [3,]  0.1631432
 [4,]  0.1631432
 [5,]  0.1631432
 [6,]  0.1631432
 [7,]  1.1422527
 [8,]  0.7207471
 [9,]  0.9519266
> 
> ### uncensored, time-varying coefficints in both groups
> mydata <- data.frame(y = y, g = g)
> m <- model(response = c(blog = lb, bBern = Bb), 
+            interacting = as.basis(~ g, data = mydata),
+            todist = "MinExtrVal")
> coef(opt <- mlt(m, data = mydata))
Note: method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dgTMatrix#dgCMatrix'.
 "TsparseMatrix#sparseMatrix" would also be valid
Gradient[1] "Mean relative difference: 9.239765e-08"
Hessian:[1] "Mean relative difference: 1.815827e-08"
               [,1]
 [1,]  0.8083708893
 [2,] -0.0584612835
 [3,] -0.0584612686
 [4,] -0.0584612537
 [5,] -0.0584612388
 [6,] -0.0584612239
 [7,]  0.7439834277
 [8,] -0.1426383973
 [9,] -0.0009466315
[10,]  1.2858419034
[11,]  1.2858419034
[12,]  1.2858419034
[13,]  1.2858419034
[14,]  1.0669816206
[15,]  0.1693281946
[16,]  1.0341447270
[17,]  1.0341447270
[18,]  1.0341447270
[19,]  1.0341447270
[20,]  2.8551343009
[21,]  2.0526896642
Warning messages:
1: In spg(par = theta, fn = loglikfct, gr = scorefct, project = "projectLinear",  :
  Unsuccessful convergence.
2: In spg(par = theta, fn = loglikfct, gr = scorefct, project = "projectLinear",  :
  Unsuccessful convergence.
3: In .mlt_fit(object = list(theta = c(0.100000014901161, -0.250000037252903,  :
  algorithm did not converge
> coef(cph <- coxph(Surv(y, rep(TRUE, nrow(mydata))) ~ g, data = mydata))
      g2       g3 
0.699808 1.022699 
> ## visualize
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> proc.time()
   user  system elapsed 
  5.927   0.071   5.989 
