
R version 3.1.3 (2015-03-09) -- "Smooth Sidewalk"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> library("mlt")
Loading required package: basefun
Loading required package: Matrix
Loading required package: polynom
Loading required package: numDeriv
> library("survival")
> set.seed(29)
> 
> ### true dgp
> rY <- function(n, ...) rexp(n, ...)
> pY <- function(x, ...) pexp(x, ...)
> dY <- function(x, ...) dexp(x, ...)
> 
> ### tree groups
> gf <- gl(3, 1)
> g <- rep(gf, 100)
> y <- rY(length(g), rate = (1:nlevels(g))[g])
> mydata <- data.frame(y = y, g = g)
> 
> boxplot(y ~ g, data = mydata)
> 
> ### uncensored, Cox model, h = bernstein
> Bb <- Bernstein_basis(order = 5, support = c(0, max(y) + .1),
+                       ui = "increasing", var = "y")
> s <- as.basis(~ g, data = data.frame(g = gf), remove_intercept = TRUE)
> m <- model(response = Bb, shifting = s, todist = "MinExtrVal")
> (cf1 <- coef(opt <- mlt(m, data = mydata)))
iter:  0  f-value:  1172.049  pgrad:  155.3215 
iter:  10  f-value:  250.4864  pgrad:  1.504704 
iter:  20  f-value:  250.2942  pgrad:  0.02292869 
iter:  30  f-value:  250.2942  pgrad:  0.0007445292 
iter:  0  f-value:  250.2942  pgrad:  4.217985e-05 
Score: 1  Hessian: 3.475601e-08 
    Bs1(y)     Bs2(y)     Bs3(y)     Bs4(y)     Bs5(y)     Bs6(y)         g2 
-2.5706854  1.1035969  1.1035969  1.1035969  1.1035969  1.8004135  0.9323847 
        g3 
 1.2627565 
Warning message:
In mlt(m, data = mydata) : NB not met
> coef(cph <- coxph(Surv(y, rep(TRUE, nrow(mydata))) ~ g, data = mydata))
      g2       g3 
0.699808 1.022699 
> yn <- generate(Bb, 50)$y
> yn <- yn[yn > 0]
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn, type = "trafo"), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> ### h = c(log, bernstein)
> lb <- log_basis(varname = "y", support = c(0, max(y)))
> m <- model(response = c(blog = lb, bBern = Bb), shifting = s, todist = "MinExtrVal")
> (cf1 <- coef(opt <- mlt(m, data = mydata)))
iter:  0  f-value:  1172.049  pgrad:  3490.335 
iter:  10  f-value:  1036.073  pgrad:  146.6784 
iter:  20  f-value:  893.2685  pgrad:  122.1464 
iter:  30  f-value:  737.2778  pgrad:  121.0265 
iter:  40  f-value:  555.2837  pgrad:  67.42464 
iter:  50  f-value:  404.7733  pgrad:  53.33427 
iter:  60  f-value:  265.0167  pgrad:  131.5255 
iter:  70  f-value:  152.8268  pgrad:  5.381906 
iter:  80  f-value:  145.6671  pgrad:  2.204127 
iter:  90  f-value:  143.7224  pgrad:  5.283412 
iter:  100  f-value:  143.1165  pgrad:  0.4577571 
iter:  110  f-value:  143.0548  pgrad:  0.05649752 
iter:  120  f-value:  143.0539  pgrad:  0.04425167 
iter:  130  f-value:  143.0539  pgrad:  0.003772571 
iter:  140  f-value:  143.0539  pgrad:  0.04632956 
iter:  0  f-value:  143.0539  pgrad:  2.693297e-05 
Score: 1.000048  Hessian: 4.557052e-05 
      log(y)       Bs1(y)       Bs2(y)       Bs3(y)       Bs4(y)       Bs5(y) 
 0.838725385 -0.305711507 -0.002511633 -0.002511633 -0.002511633 -0.002511633 
      Bs6(y)           g2           g3 
 0.275021612  0.764302979  1.068695172 
Warning message:
In mlt(m, data = mydata) : NB not met
> ## sample from this model
> nd <- samplefrom(opt, newdata = data.frame(g = gf), n = 100)
> (cf2 <- coef(opt2 <- mlt(m, data = nd)))
iter:  0  f-value:  614.629  pgrad:  1976.324 
iter:  10  f-value:  170.4926  pgrad:  5.269111 
iter:  20  f-value:  166.3629  pgrad:  1.101502 
iter:  30  f-value:  166.3292  pgrad:  0.3182641 
iter:  40  f-value:  166.3169  pgrad:  1.100289 
iter:  50  f-value:  166.3125  pgrad:  0.06924305 
iter:  60  f-value:  166.3119  pgrad:  0.02088792 
iter:  70  f-value:  166.3119  pgrad:  0.1866517 
iter:  80  f-value:  166.3118  pgrad:  0.008585567 
iter:  90  f-value:  166.3118  pgrad:  0.01238711 
iter:  100  f-value:  166.3118  pgrad:  0.003838084 
iter:  110  f-value:  166.3118  pgrad:  0.001671991 
iter:  120  f-value:  166.3118  pgrad:  0.0008328308 
iter:  130  f-value:  166.3118  pgrad:  0.0002626939 
iter:  140  f-value:  166.3118  pgrad:  0.0001338238 
iter:  0  f-value:  166.3118  pgrad:  0.0005293021 
Score: 1.000092  Hessian: 5.399906e-09 
    log(y)     Bs1(y)     Bs2(y)     Bs3(y)     Bs4(y)     Bs5(y)     Bs6(y) 
 1.0961749 -0.2231685 -0.2231685 -0.2231685 -0.2231685 -0.2231685  0.5456470 
        g2         g3 
 0.8772917  1.0475215 
Warning message:
In mlt(m, data = nd) : NB not met
> cf1 - cf2
     log(y)      Bs1(y)      Bs2(y)      Bs3(y)      Bs4(y)      Bs5(y) 
-0.25744956 -0.08254298  0.22065689  0.22065689  0.22065689  0.22065689 
     Bs6(y)          g2          g3 
-0.27062535 -0.11298872  0.02117371 
> ## visualise
> yn <- generate(Bb, 50)$y
> yn <- yn[yn > 0]
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn, type = "trafo"), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> ### right censoring
> mydata <- data.frame(y = Surv(y, sample(0:1, length(y), replace = TRUE)), g = g)
> coef(opt <- mlt(m, data = mydata))
iter:  0  f-value:  383.6134  pgrad:  1166.03 
iter:  10  f-value:  177.233  pgrad:  5.671069 
iter:  20  f-value:  172.6599  pgrad:  1.201682 
iter:  30  f-value:  171.8665  pgrad:  0.1912543 
iter:  40  f-value:  171.849  pgrad:  0.02141614 
iter:  50  f-value:  171.8489  pgrad:  0.2581689 
iter:  60  f-value:  171.8488  pgrad:  0.1596473 
iter:  70  f-value:  171.8488  pgrad:  0.0008484644 
iter:  80  f-value:  171.8488  pgrad:  0.0001691553 
iter:  0  f-value:  171.8488  pgrad:  8.202335e-05 
Score: 1.000037  Hessian: 3.762379e-09 
    log(y)     Bs1(y)     Bs2(y)     Bs3(y)     Bs4(y)     Bs5(y)     Bs6(y) 
 0.8548851 -0.8701502 -0.7839373 -0.7839373 -0.7839373 -0.7839373 -0.2774294 
        g2         g3 
 0.8692651  1.1418627 
Warning message:
In mlt(m, data = mydata) : NB not met
> coef(cph <- coxph(y ~ g, data = mydata))
       g2        g3 
0.7891759 1.0616941 
> 
> ### left censoring
> mydata <- data.frame(y = Surv(y, sample(0:1, length(y), replace = TRUE), type = "left"), g = g)
> coef(opt <- mlt(m, data = mydata))
iter:  0  f-value:  367.327  pgrad:  797.7525 
iter:  10  f-value:  189.6535  pgrad:  4.902632 
iter:  20  f-value:  183.9513  pgrad:  2.09891 
iter:  30  f-value:  182.803  pgrad:  2.65925 
iter:  40  f-value:  182.684  pgrad:  3.571788 
iter:  50  f-value:  182.5838  pgrad:  0.4204601 
iter:  60  f-value:  182.5827  pgrad:  0.006968374 
iter:  70  f-value:  182.5827  pgrad:  0.001111518 
iter:  0  f-value:  182.5827  pgrad:  0.0002091207 
Score: 1.002478  Hessian: 5.843507e-07 
     log(y)      Bs1(y)      Bs2(y)      Bs3(y)      Bs4(y)      Bs5(y) 
 0.38199595 -0.04273472  0.97761784  0.97761784  0.97761784  0.97761784 
     Bs6(y)          g2          g3 
 1.19850853  0.33286181  0.53879833 
Warning message:
In mlt(m, data = mydata) : NB not met
> 
> ### interval censoring
> Bb <- Bernstein_basis(order = 5, support = c(0, max(y + 1) + .1),
+                       ui = "increasing", var = "y")
> mydata <- data.frame(y = Surv(y, y + 1, sample(0:3, length(y), replace = TRUE), type = "interval"), 
+                      g = g)
> m <- model(response = c(blog = lb, bBern = Bb), shifting = s, todist = "MinExtrVal")
> coef(opt <- mlt(m, data = mydata))
iter:  0  f-value:  467.1058  pgrad:  1024.095 
iter:  10  f-value:  271.4119  pgrad:  6.003445 
iter:  20  f-value:  270.8209  pgrad:  57.59695 
iter:  30  f-value:  266.9112  pgrad:  0.7347728 
iter:  40  f-value:  266.8112  pgrad:  0.6341064 
iter:  50  f-value:  266.6898  pgrad:  3.171266 
iter:  60  f-value:  266.6771  pgrad:  0.04096962 
iter:  70  f-value:  266.6769  pgrad:  0.05166548 
iter:  80  f-value:  266.6769  pgrad:  0.01195919 
iter:  90  f-value:  266.6768  pgrad:  0.004475353 
iter:  100  f-value:  266.6768  pgrad:  0.002415328 
iter:  110  f-value:  266.6768  pgrad:  0.008663178 
iter:  120  f-value:  266.6768  pgrad:  0.00084859 
iter:  130  f-value:  266.6768  pgrad:  0.0001270865 
iter:  0  f-value:  266.6768  pgrad:  7.609833e-05 
Score: 1.000417  Hessian: 2.196235e-08 
    log(y)     Bs1(y)     Bs2(y)     Bs3(y)     Bs4(y)     Bs5(y)     Bs6(y) 
 0.5103155 -1.2644931  0.1631480  0.1631480  0.1631480  0.1631480  1.1422746 
        g2         g3 
 0.7207476  0.9519270 
Warning message:
In mlt(m, data = mydata) : NB not met
> 
> ### uncensored, time-varying coefficints in both groups
> mydata <- data.frame(y = y, g = g)
> m <- model(response = c(blog = lb, bBern = Bb), 
+            interacting = as.basis(~ g, data = mydata),
+            todist = "MinExtrVal")
> coef(opt <- mlt(m, data = mydata))
Note: method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dgTMatrix#dgCMatrix'.
 "TsparseMatrix#sparseMatrix" would also be valid
iter:  0  f-value:  1172.049  pgrad:  3490.335 
iter:  10  f-value:  977.543  pgrad:  159.0634 
iter:  20  f-value:  918.6962  pgrad:  127.736 
iter:  30  f-value:  874.1853  pgrad:  120.4901 
iter:  40  f-value:  840.9982  pgrad:  114.9732 
iter:  50  f-value:  814.9448  pgrad:  110.594 
iter:  60  f-value:  793.4527  pgrad:  106.9574 
iter:  70  f-value:  774.6972  pgrad:  103.7781 
iter:  80  f-value:  756.0076  pgrad:  100.5405 
iter:  90  f-value:  735.7345  pgrad:  97.41875 
iter:  100  f-value:  711.3349  pgrad:  92.92684 
iter:  110  f-value:  657.8514  pgrad:  85.09987 
iter:  120  f-value:  628.0069  pgrad:  78.66901 
iter:  130  f-value:  606.8618  pgrad:  76.39388 
iter:  140  f-value:  578.0783  pgrad:  70.36826 
iter:  150  f-value:  559.1158  pgrad:  432.9083 
iter:  160  f-value:  541.7943  pgrad:  64.69371 
iter:  170  f-value:  523.4337  pgrad:  61.35043 
iter:  180  f-value:  503.8836  pgrad:  501.4526 
iter:  190  f-value:  485.9419  pgrad:  55.62903 
iter:  200  f-value:  466.8449  pgrad:  52.28399 
iter:  0  f-value:  463.9289  pgrad:  552.7201 
iter:  10  f-value:  445.6406  pgrad:  49.2836 
iter:  20  f-value:  426.1579  pgrad:  45.99234 
iter:  30  f-value:  405.8299  pgrad:  628.7636 
iter:  40  f-value:  386.4591  pgrad:  40.34351 
iter:  50  f-value:  360.515  pgrad:  81.78699 
iter:  60  f-value:  327.5892  pgrad:  31.78598 
iter:  70  f-value:  283.7185  pgrad:  41.5047 
iter:  80  f-value:  259.7974  pgrad:  23.87435 
iter:  90  f-value:  180.5311  pgrad:  20.78776 
iter:  100  f-value:  175.6101  pgrad:  7.078616 
iter:  110  f-value:  157.4205  pgrad:  90.9457 
iter:  120  f-value:  148.381  pgrad:  3.449826 
iter:  130  f-value:  144.6183  pgrad:  2.066298 
iter:  140  f-value:  143.834  pgrad:  11.63972 
iter:  150  f-value:  141.9648  pgrad:  0.8263844 
iter:  160  f-value:  141.6237  pgrad:  0.8126058 
iter:  170  f-value:  141.2204  pgrad:  2.488713 
iter:  180  f-value:  140.4218  pgrad:  1.724857 
iter:  190  f-value:  140.2648  pgrad:  0.4230284 
iter:  200  f-value:  139.7238  pgrad:  0.7806094 
iter:  210  f-value:  139.6369  pgrad:  0.5700025 
iter:  220  f-value:  139.6316  pgrad:  8.480994 
iter:  230  f-value:  139.5522  pgrad:  0.2024501 
iter:  240  f-value:  139.5336  pgrad:  0.732102 
iter:  250  f-value:  139.4627  pgrad:  0.4312322 
iter:  260  f-value:  139.4549  pgrad:  0.1257984 
iter:  270  f-value:  139.4421  pgrad:  0.7546099 
iter:  280  f-value:  139.4293  pgrad:  0.1172349 
iter:  290  f-value:  139.4213  pgrad:  0.7617348 
iter:  300  f-value:  139.3978  pgrad:  0.1293952 
iter:  310  f-value:  139.39  pgrad:  0.09840883 
iter:  320  f-value:  139.3864  pgrad:  0.6462097 
iter:  330  f-value:  139.3823  pgrad:  0.09115728 
iter:  340  f-value:  139.3786  pgrad:  0.08876855 
iter:  350  f-value:  139.3623  pgrad:  0.1370408 
iter:  360  f-value:  139.3592  pgrad:  0.07044028 
iter:  370  f-value:  139.3571  pgrad:  0.6431351 
iter:  380  f-value:  139.3493  pgrad:  0.05715306 
iter:  390  f-value:  139.3476  pgrad:  0.05351928 
iter:  400  f-value:  139.343  pgrad:  0.04824764 
iter:  410  f-value:  139.3419  pgrad:  0.9014517 
iter:  420  f-value:  139.3404  pgrad:  0.04682992 
iter:  430  f-value:  139.3388  pgrad:  0.04628114 
iter:  440  f-value:  139.3384  pgrad:  1.272769 
iter:  450  f-value:  139.3363  pgrad:  0.04448769 
iter:  460  f-value:  139.3348  pgrad:  0.04354019 
iter:  470  f-value:  139.3338  pgrad:  0.1722809 
iter:  480  f-value:  139.3328  pgrad:  0.4966338 
iter:  490  f-value:  139.3321  pgrad:  0.1211155 
iter:  500  f-value:  139.3317  pgrad:  0.04176392 
iter:  510  f-value:  139.3303  pgrad:  0.04066809 
iter:  520  f-value:  139.3305  pgrad:  0.7773127 
iter:  530  f-value:  139.3298  pgrad:  0.03771393 
iter:  540  f-value:  139.3296  pgrad:  0.114964 
iter:  550  f-value:  139.329  pgrad:  0.03704587 
iter:  560  f-value:  139.3285  pgrad:  0.03708622 
iter:  570  f-value:  139.3282  pgrad:  0.6426931 
iter:  580  f-value:  139.3274  pgrad:  0.04512354 
iter:  590  f-value:  139.3271  pgrad:  0.03613182 
iter:  600  f-value:  139.3268  pgrad:  0.1152642 
iter:  610  f-value:  139.3262  pgrad:  0.03611088 
iter:  620  f-value:  139.3252  pgrad:  0.0359552 
iter:  630  f-value:  139.3248  pgrad:  0.1937182 
iter:  640  f-value:  139.3229  pgrad:  0.03558776 
iter:  650  f-value:  139.3223  pgrad:  0.03546473 
iter:  660  f-value:  139.322  pgrad:  0.03548733 
iter:  670  f-value:  139.3218  pgrad:  0.0354754 
iter:  680  f-value:  139.3215  pgrad:  0.03652618 
iter:  690  f-value:  139.3212  pgrad:  0.09603228 
iter:  700  f-value:  139.3205  pgrad:  0.03524912 
iter:  710  f-value:  139.3198  pgrad:  0.05276572 
iter:  720  f-value:  139.3195  pgrad:  0.03524574 
iter:  730  f-value:  139.3195  pgrad:  0.7610823 
iter:  740  f-value:  139.319  pgrad:  0.0349944 
iter:  750  f-value:  139.3187  pgrad:  0.0353011 
iter:  760  f-value:  139.3157  pgrad:  0.1274755 
iter:  770  f-value:  139.3154  pgrad:  0.03456297 
iter:  780  f-value:  139.3147  pgrad:  0.03451424 
iter:  790  f-value:  139.3144  pgrad:  0.03441347 
iter:  800  f-value:  139.3141  pgrad:  0.1097833 
iter:  810  f-value:  139.3136  pgrad:  0.03436346 
iter:  820  f-value:  139.3133  pgrad:  0.03436004 
iter:  830  f-value:  139.3064  pgrad:  0.03323038 
iter:  840  f-value:  139.3061  pgrad:  0.03337409 
iter:  850  f-value:  139.3056  pgrad:  0.09663841 
iter:  860  f-value:  139.3055  pgrad:  0.03308734 
iter:  870  f-value:  139.304  pgrad:  0.03295526 
iter:  880  f-value:  139.3037  pgrad:  0.2251942 
iter:  890  f-value:  139.3033  pgrad:  0.03273657 
iter:  900  f-value:  139.3032  pgrad:  0.0327441 
iter:  910  f-value:  139.3026  pgrad:  0.03269178 
iter:  920  f-value:  139.3024  pgrad:  0.2095404 
iter:  930  f-value:  139.3022  pgrad:  0.03265244 
iter:  940  f-value:  139.302  pgrad:  0.0614554 
iter:  950  f-value:  139.3017  pgrad:  0.03259357 
iter:  960  f-value:  139.3015  pgrad:  0.03269477 
iter:  970  f-value:  139.3008  pgrad:  0.3808886 
iter:  980  f-value:  139.3005  pgrad:  0.0323499 
iter:  990  f-value:  139.3003  pgrad:  0.289091 
iter:  1000  f-value:  139.2999  pgrad:  0.0322829 
iter:  1010  f-value:  139.2992  pgrad:  0.03209991 
iter:  1020  f-value:  139.2984  pgrad:  0.03203058 
iter:  1030  f-value:  139.2986  pgrad:  0.7104011 
iter:  1040  f-value:  139.2981  pgrad:  0.5307028 
iter:  1050  f-value:  139.2947  pgrad:  0.03284963 
iter:  1060  f-value:  139.2945  pgrad:  0.03143788 
iter:  1070  f-value:  139.294  pgrad:  0.03132876 
iter:  1080  f-value:  139.2938  pgrad:  0.03133009 
iter:  1090  f-value:  139.2932  pgrad:  0.03121783 
iter:  1100  f-value:  139.2925  pgrad:  0.08054364 
iter:  1110  f-value:  139.2923  pgrad:  0.03107289 
iter:  1120  f-value:  139.292  pgrad:  0.03119307 
iter:  1130  f-value:  139.2918  pgrad:  0.03381395 
iter:  1140  f-value:  139.2915  pgrad:  0.03116056 
iter:  1150  f-value:  139.2909  pgrad:  0.1724729 
iter:  1160  f-value:  139.2907  pgrad:  0.03094547 
iter:  1170  f-value:  139.2905  pgrad:  0.07066312 
iter:  1180  f-value:  139.2903  pgrad:  0.03081369 
iter:  1190  f-value:  139.2896  pgrad:  0.03071885 
iter:  1200  f-value:  139.2894  pgrad:  0.07592033 
iter:  1210  f-value:  139.2892  pgrad:  0.03083087 
iter:  1220  f-value:  139.2891  pgrad:  0.09494361 
iter:  1230  f-value:  139.2889  pgrad:  0.03063787 
iter:  1240  f-value:  139.2888  pgrad:  0.03283158 
iter:  1250  f-value:  139.2885  pgrad:  0.08148585 
iter:  1260  f-value:  139.2883  pgrad:  0.03056687 
iter:  1270  f-value:  139.2881  pgrad:  0.03084399 
iter:  1280  f-value:  139.2876  pgrad:  0.08852581 
iter:  1290  f-value:  139.287  pgrad:  0.04271456 
iter:  1300  f-value:  139.2868  pgrad:  0.5029925 
iter:  1310  f-value:  139.286  pgrad:  0.66732 
iter:  1320  f-value:  139.2855  pgrad:  0.2310555 
iter:  1330  f-value:  139.2852  pgrad:  0.03008485 
iter:  1340  f-value:  139.285  pgrad:  0.3388457 
iter:  1350  f-value:  139.2847  pgrad:  0.5932667 
iter:  1360  f-value:  139.2843  pgrad:  0.02987943 
iter:  1370  f-value:  139.2841  pgrad:  0.07800169 
iter:  1380  f-value:  139.2839  pgrad:  0.02984471 
iter:  1390  f-value:  139.2839  pgrad:  0.609069 
iter:  1400  f-value:  139.2835  pgrad:  0.02974336 
iter:  1410  f-value:  139.2832  pgrad:  0.02967116 
iter:  1420  f-value:  139.283  pgrad:  0.1653494 
iter:  1430  f-value:  139.2821  pgrad:  0.02954433 
iter:  1440  f-value:  139.2819  pgrad:  0.02971287 
iter:  1450  f-value:  139.2818  pgrad:  0.5178854 
iter:  1460  f-value:  139.2813  pgrad:  0.04103176 
iter:  1470  f-value:  139.2811  pgrad:  0.02944278 
iter:  1480  f-value:  139.2809  pgrad:  0.3590411 
iter:  1490  f-value:  139.2793  pgrad:  0.04657814 
iter:  1500  f-value:  139.2792  pgrad:  0.02906048 
iter:  0  f-value:  139.2753  pgrad:  0.2414528 
iter:  10  f-value:  139.275  pgrad:  0.02859042 
iter:  20  f-value:  139.2749  pgrad:  0.02840774 
iter:  30  f-value:  139.2747  pgrad:  0.1181665 
iter:  40  f-value:  139.2744  pgrad:  0.1041404 
iter:  50  f-value:  139.2742  pgrad:  0.02841213 
iter:  60  f-value:  139.2741  pgrad:  0.02823845 
iter:  70  f-value:  139.2736  pgrad:  0.02830882 
iter:  80  f-value:  139.2734  pgrad:  0.05536554 
iter:  90  f-value:  139.2733  pgrad:  0.02811749 
iter:  100  f-value:  139.2729  pgrad:  0.03430952 
iter:  110  f-value:  139.2728  pgrad:  0.238565 
iter:  120  f-value:  139.2719  pgrad:  0.03884945 
iter:  130  f-value:  139.2717  pgrad:  0.02788359 
iter:  140  f-value:  139.2716  pgrad:  0.3088252 
iter:  150  f-value:  139.2714  pgrad:  0.02778348 
iter:  160  f-value:  139.2713  pgrad:  0.3345669 
iter:  170  f-value:  139.2711  pgrad:  0.02782133 
iter:  180  f-value:  139.2708  pgrad:  0.3367597 
iter:  190  f-value:  139.2706  pgrad:  0.02767693 
iter:  200  f-value:  139.2704  pgrad:  0.3510536 
iter:  210  f-value:  139.2702  pgrad:  0.02760147 
iter:  220  f-value:  139.2701  pgrad:  0.3388329 
iter:  230  f-value:  139.2699  pgrad:  0.02762603 
iter:  240  f-value:  139.2697  pgrad:  0.08163503 
iter:  250  f-value:  139.2692  pgrad:  0.1517811 
iter:  260  f-value:  139.269  pgrad:  0.274019 
iter:  270  f-value:  139.2688  pgrad:  0.02751684 
iter:  280  f-value:  139.2687  pgrad:  0.1098769 
iter:  290  f-value:  139.2685  pgrad:  0.02730067 
iter:  300  f-value:  139.2682  pgrad:  0.09233755 
iter:  310  f-value:  139.268  pgrad:  0.02746877 
iter:  320  f-value:  139.2667  pgrad:  0.09048623 
iter:  330  f-value:  139.2665  pgrad:  0.02699437 
iter:  340  f-value:  139.2662  pgrad:  0.02759692 
iter:  350  f-value:  139.2662  pgrad:  0.3013729 
iter:  360  f-value:  139.266  pgrad:  0.02686928 
iter:  370  f-value:  139.2654  pgrad:  0.02676329 
iter:  380  f-value:  139.2652  pgrad:  0.2012861 
iter:  390  f-value:  139.2651  pgrad:  0.02672087 
iter:  400  f-value:  139.2648  pgrad:  0.0753199 
iter:  410  f-value:  139.2646  pgrad:  0.07286713 
iter:  420  f-value:  139.2644  pgrad:  0.1465651 
iter:  430  f-value:  139.2637  pgrad:  0.02872584 
iter:  440  f-value:  139.2635  pgrad:  0.02665566 
iter:  450  f-value:  139.2633  pgrad:  0.02647955 
iter:  460  f-value:  139.2626  pgrad:  0.02631729 
iter:  470  f-value:  139.2624  pgrad:  0.2917755 
iter:  480  f-value:  139.2622  pgrad:  0.02623129 
iter:  490  f-value:  139.262  pgrad:  0.3451826 
iter:  500  f-value:  139.2618  pgrad:  0.1653381 
iter:  510  f-value:  139.2616  pgrad:  0.02630089 
iter:  520  f-value:  139.2614  pgrad:  0.02631376 
iter:  530  f-value:  139.2612  pgrad:  0.02608497 
iter:  540  f-value:  139.2607  pgrad:  0.02600433 
iter:  550  f-value:  139.2604  pgrad:  0.09574866 
iter:  560  f-value:  139.2603  pgrad:  0.02595327 
iter:  570  f-value:  139.2601  pgrad:  0.02587828 
iter:  580  f-value:  139.2598  pgrad:  0.02583746 
iter:  590  f-value:  139.2595  pgrad:  0.02584181 
iter:  600  f-value:  139.2591  pgrad:  0.1279831 
iter:  610  f-value:  139.259  pgrad:  0.02572738 
iter:  620  f-value:  139.2587  pgrad:  0.02564746 
iter:  630  f-value:  139.2585  pgrad:  0.2779743 
iter:  640  f-value:  139.2583  pgrad:  0.03466868 
iter:  650  f-value:  139.2583  pgrad:  0.02559046 
iter:  660  f-value:  139.2572  pgrad:  0.0253986 
iter:  670  f-value:  139.2569  pgrad:  0.02533528 
iter:  680  f-value:  139.2564  pgrad:  0.05190627 
iter:  690  f-value:  139.2563  pgrad:  0.02541324 
iter:  700  f-value:  139.2562  pgrad:  0.02518773 
iter:  710  f-value:  139.256  pgrad:  0.02530681 
iter:  720  f-value:  139.2557  pgrad:  0.1505352 
iter:  730  f-value:  139.2556  pgrad:  0.02512993 
iter:  740  f-value:  139.2554  pgrad:  0.1193255 
iter:  750  f-value:  139.2552  pgrad:  0.02506214 
iter:  760  f-value:  139.2545  pgrad:  1.003097 
iter:  770  f-value:  139.2542  pgrad:  0.885623 
iter:  780  f-value:  139.2531  pgrad:  0.1511587 
iter:  790  f-value:  139.2526  pgrad:  0.07527259 
iter:  800  f-value:  139.2521  pgrad:  0.02460963 
iter:  810  f-value:  139.252  pgrad:  0.02447158 
iter:  820  f-value:  139.2512  pgrad:  0.02429047 
iter:  830  f-value:  139.251  pgrad:  0.1113852 
iter:  840  f-value:  139.2509  pgrad:  0.02427368 
iter:  850  f-value:  139.2507  pgrad:  0.02431421 
iter:  860  f-value:  139.2506  pgrad:  0.06395734 
iter:  870  f-value:  139.2505  pgrad:  0.02431305 
iter:  880  f-value:  139.2504  pgrad:  0.02418457 
iter:  890  f-value:  139.2502  pgrad:  0.02413973 
iter:  900  f-value:  139.2501  pgrad:  0.02425093 
iter:  910  f-value:  139.2501  pgrad:  0.4760169 
iter:  920  f-value:  139.2497  pgrad:  0.05066694 
iter:  930  f-value:  139.2494  pgrad:  0.1070768 
iter:  940  f-value:  139.2493  pgrad:  0.1931755 
iter:  950  f-value:  139.2492  pgrad:  0.0239766 
iter:  960  f-value:  139.249  pgrad:  0.02394688 
iter:  970  f-value:  139.2488  pgrad:  0.03997122 
iter:  980  f-value:  139.2487  pgrad:  0.3256235 
iter:  990  f-value:  139.2474  pgrad:  0.02371619 
iter:  1000  f-value:  139.2472  pgrad:  0.02357862 
iter:  1010  f-value:  139.247  pgrad:  0.023577 
iter:  1020  f-value:  139.2465  pgrad:  0.02375323 
iter:  1030  f-value:  139.2463  pgrad:  0.02343101 
iter:  1040  f-value:  139.2458  pgrad:  0.4812323 
iter:  1050  f-value:  139.2456  pgrad:  0.02329759 
iter:  1060  f-value:  139.2454  pgrad:  0.02786568 
iter:  1070  f-value:  139.2452  pgrad:  0.08403751 
iter:  1080  f-value:  139.2451  pgrad:  0.02338801 
iter:  1090  f-value:  139.2447  pgrad:  0.6654418 
iter:  1100  f-value:  139.2438  pgrad:  0.301148 
iter:  1110  f-value:  139.2437  pgrad:  0.02294683 
iter:  1120  f-value:  139.2435  pgrad:  0.02294718 
iter:  1130  f-value:  139.2434  pgrad:  0.02309247 
iter:  1140  f-value:  139.2434  pgrad:  0.5332551 
iter:  1150  f-value:  139.243  pgrad:  0.02282532 
iter:  1160  f-value:  139.2429  pgrad:  0.07343958 
iter:  1170  f-value:  139.2428  pgrad:  0.1508466 
iter:  1180  f-value:  139.2424  pgrad:  0.102546 
iter:  1190  f-value:  139.242  pgrad:  0.05368222 
iter:  1200  f-value:  139.2418  pgrad:  0.02255666 
iter:  1210  f-value:  139.2402  pgrad:  0.02227567 
iter:  1220  f-value:  139.2401  pgrad:  0.02228959 
iter:  1230  f-value:  139.24  pgrad:  0.5291333 
iter:  1240  f-value:  139.2397  pgrad:  0.0222465 
iter:  1250  f-value:  139.2397  pgrad:  0.2593211 
iter:  1260  f-value:  139.2395  pgrad:  0.02220359 
iter:  1270  f-value:  139.2395  pgrad:  0.2539473 
iter:  1280  f-value:  139.2394  pgrad:  0.02215257 
iter:  1290  f-value:  139.2393  pgrad:  0.302071 
iter:  1300  f-value:  139.2391  pgrad:  0.02207248 
iter:  1310  f-value:  139.239  pgrad:  0.02200116 
iter:  1320  f-value:  139.2388  pgrad:  0.0407795 
iter:  1330  f-value:  139.2386  pgrad:  0.05810242 
iter:  1340  f-value:  139.2385  pgrad:  0.2170084 
iter:  1350  f-value:  139.2385  pgrad:  0.5073669 
iter:  1360  f-value:  139.2382  pgrad:  0.0218835 
iter:  1370  f-value:  139.2381  pgrad:  0.02197524 
iter:  1380  f-value:  139.238  pgrad:  0.1297298 
iter:  1390  f-value:  139.2379  pgrad:  0.0217988 
iter:  1400  f-value:  139.2378  pgrad:  0.2899305 
iter:  1410  f-value:  139.2376  pgrad:  0.02189065 
iter:  1420  f-value:  139.2375  pgrad:  0.03884179 
iter:  1430  f-value:  139.2374  pgrad:  0.0226957 
iter:  1440  f-value:  139.2373  pgrad:  0.02183746 
iter:  1450  f-value:  139.2371  pgrad:  0.02166455 
iter:  1460  f-value:  139.2367  pgrad:  0.0215851 
iter:  1470  f-value:  139.2367  pgrad:  0.3912007 
iter:  1480  f-value:  139.2365  pgrad:  0.02155372 
iter:  1490  f-value:  139.2363  pgrad:  0.02152136 
iter:  1500  f-value:  139.2362  pgrad:  0.05660432 
Score: 1.000049  Hessian: 0.0002516353 
log(y):(Intercept) Bs1(y):(Intercept) Bs2(y):(Intercept) Bs3(y):(Intercept) 
       0.808340843       -0.058433754       -0.058433754       -0.058433754 
Bs4(y):(Intercept) Bs5(y):(Intercept) Bs6(y):(Intercept)          log(y):g2 
      -0.058433754       -0.058433754        0.744667960       -0.142467909 
         Bs1(y):g2          Bs2(y):g2          Bs3(y):g2          Bs4(y):g2 
      -0.001203481        1.286169094        1.286169094        1.286169094 
         Bs5(y):g2          Bs6(y):g2          log(y):g3          Bs1(y):g3 
       1.286169094        0.995002524        0.170138774        1.035503113 
         Bs2(y):g3          Bs3(y):g3          Bs4(y):g3          Bs5(y):g3 
       1.035503113        1.035503113        1.035503113        2.638841580 
         Bs6(y):g3 
       1.835739866 
Warning messages:
1: In mlt(m, data = mydata) : NB not met
2: In spg(par = beta, fn = loglikfct, gr = scorefct, project = "projectLinear",  :
  Unsuccessful convergence.
3: In spg(par = beta, fn = loglikfct, gr = scorefct, project = "projectLinear",  :
  Unsuccessful convergence.
4: In spg(par = beta, fn = loglikfct, gr = scorefct, project = "projectLinear",  :
  Unsuccessful convergence.
5: In mlt(m, data = mydata) : algorithm did not converge
> coef(cph <- coxph(Surv(y, rep(TRUE, nrow(mydata))) ~ g, data = mydata))
      g2       g3 
0.699808 1.022699 
> ## visualize
> a <- predict(opt, newdata = data.frame(g = gf))
> layout(matrix(1:4, ncol = 2))
> plot(yn, a[[1]](yn), type = "l", col = "red")
> lines(yn, log(yn))
> plot(yn, 1 - a[[1]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[1])))
> plot(yn, 1 - a[[2]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[2])))
> plot(yn, 1 - a[[3]](yn, type = "prob"), type = "l", col = "red", ylim = c(0, 1))
> lines(survfit(cph, newdata = data.frame(g = gf[3])))
> 
> proc.time()
   user  system elapsed 
  6.676   0.091   6.758 
